#!/usr/bin/env python3
"""
map01_storm_vulnerability.py — IONIS-V11-MAP-01: Geomagnetic Vulnerability Map

Generate a global heatmap of the V11 storm_scaler gate values from real
WSPR path data to prove the model "discovered" polar auroral zones as
regions of amplified geomagnetic storm impact — without being given
geographic boundaries.

Method:
  1. Load the 10M-row training dataset (real WSPR paths)
  2. Engineer features and extract storm_gate for every path
  3. Compute path midpoint (lat, lon) from Maidenhead grids
  4. Bin by 5° lat × 5° lon and plot mean storm_gate per cell

The storm gate depends ONLY on the 11 geography/time features (the DNN
trunk), not on SFI or Kp. This map reveals the model's internal belief
about which regions of the globe are most vulnerable to geomagnetic
storms — learned purely from data, with no geographic priors.

Output:
  - Global heatmap: Red = High storm sensitivity, Blue = Low
  - Latitude profile: Zonal mean storm gate vs latitude
  - Reference: Auroral oval bands at ±60°–70°
  - PNG saved to docs and training repos
"""

import os
import re
import math
import time
import logging

import numpy as np
import pandas as pd
import torch
import torch.nn as nn

import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from matplotlib.colors import TwoSlopeNorm

# --- CONFIGURATION ---
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
TRAINING_DIR = os.path.dirname(SCRIPT_DIR)
CHECKPOINT_PATH = os.path.join(TRAINING_DIR, "models", "ionis_v11_phaseC.pth")
CSV_PATH = os.path.join(TRAINING_DIR, "data", "training_v6_clean.csv")
DOCS_DIR = os.path.join(os.path.dirname(TRAINING_DIR), "ki7mt-ai-lab-docs",
                        "docs", "architecture")
OUTPUT_PNG = "IONIS-V11-MAP-01.png"

# Geographic binning
BIN_LAT = 5.0  # degrees
BIN_LON = 5.0  # degrees
MIN_SAMPLES = 50  # minimum paths per bin to be plotted

# Model constants
DNN_DIM = 11
SFI_IDX = 11
KP_PENALTY_IDX = 12
INPUT_DIM = 13
GATE_INIT_BIAS = -math.log(2.0)

BAND_TO_HZ = {
    102:  1_836_600,   103:  3_568_600,   104:  5_287_200,
    105:  7_038_600,   106: 10_138_700,   107: 14_097_100,
    108: 18_104_600,   109: 21_094_600,   110: 24_924_600,
    111: 28_124_600,
}

DEVICE = torch.device("mps" if torch.backends.mps.is_available() else "cpu")

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(message)s',
    datefmt='%H:%M:%S',
)
log = logging.getLogger('map01')


# ── Model Definition (inline, same as training scripts) ─────────────────

class MonotonicMLP(nn.Module):
    def __init__(self, hidden_dim=8):
        super().__init__()
        self.fc1 = nn.Linear(1, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, 1, bias=True)
        self.activation = nn.Softplus()

    def forward(self, x):
        w1 = torch.abs(self.fc1.weight)
        w2 = torch.abs(self.fc2.weight)
        h = self.activation(nn.functional.linear(x, w1, self.fc1.bias))
        return nn.functional.linear(h, w2, self.fc2.bias)


def _gate(x):
    return 0.5 + 1.5 * torch.sigmoid(x)


class IonisV11Gate(nn.Module):
    def __init__(self, dnn_dim=11, sidecar_hidden=8):
        super().__init__()
        self.trunk = nn.Sequential(
            nn.Linear(dnn_dim, 512), nn.Mish(),
            nn.Linear(512, 256), nn.Mish(),
        )
        self.base_head = nn.Sequential(
            nn.Linear(256, 128), nn.Mish(),
            nn.Linear(128, 1),
        )
        self.sun_scaler_head = nn.Sequential(
            nn.Linear(256, 64), nn.Mish(),
            nn.Linear(64, 1),
        )
        self.storm_scaler_head = nn.Sequential(
            nn.Linear(256, 64), nn.Mish(),
            nn.Linear(64, 1),
        )
        self.sun_sidecar = MonotonicMLP(hidden_dim=sidecar_hidden)
        self.storm_sidecar = MonotonicMLP(hidden_dim=sidecar_hidden)
        self._init_scaler_heads()

    def _init_scaler_heads(self):
        for head in [self.sun_scaler_head, self.storm_scaler_head]:
            final_layer = head[-1]
            nn.init.zeros_(final_layer.weight)
            nn.init.constant_(final_layer.bias, GATE_INIT_BIAS)

    def forward(self, x):
        x_deep = x[:, :DNN_DIM]
        x_sfi = x[:, SFI_IDX:SFI_IDX + 1]
        x_kp = x[:, KP_PENALTY_IDX:KP_PENALTY_IDX + 1]
        trunk_out = self.trunk(x_deep)
        base_snr = self.base_head(trunk_out)
        sun_logit = self.sun_scaler_head(trunk_out)
        storm_logit = self.storm_scaler_head(trunk_out)
        sun_gate = _gate(sun_logit)
        storm_gate = _gate(storm_logit)
        sun_boost = self.sun_sidecar(x_sfi)
        storm_boost = self.storm_sidecar(x_kp)
        return base_snr + sun_gate * sun_boost + storm_gate * storm_boost

    def get_gates(self, x):
        x_deep = x[:, :DNN_DIM]
        with torch.no_grad():
            trunk_out = self.trunk(x_deep)
            sun_logit = self.sun_scaler_head(trunk_out)
            storm_logit = self.storm_scaler_head(trunk_out)
        return _gate(sun_logit), _gate(storm_logit)


# ── Grid / Feature Utilities ────────────────────────────────────────────

GRID_RE = re.compile(r'[A-Ra-r]{2}[0-9]{2}')


def grid_to_latlon_series(grids):
    lats = np.zeros(len(grids), dtype=np.float32)
    lons = np.zeros(len(grids), dtype=np.float32)
    for i, g in enumerate(grids):
        s = str(g).strip().rstrip('\x00')
        m = GRID_RE.search(s)
        g4 = m.group(0).upper() if m else 'JJ00'
        lons[i] = (ord(g4[0]) - ord('A')) * 20.0 - 180.0 + int(g4[2]) * 2.0 + 1.0
        lats[i] = (ord(g4[1]) - ord('A')) * 10.0 - 90.0 + int(g4[3]) * 1.0 + 0.5
    return lats, lons


def engineer_features(df):
    distance = df['distance'].values.astype(np.float32)
    band = df['band'].values.astype(np.int32)
    hour = df['hour'].values.astype(np.float32)
    month = df['month'].values.astype(np.float32)
    azimuth = df['azimuth'].values.astype(np.float32)
    sfi = df['sfi'].values.astype(np.float32)
    midpoint_lat_raw = df['midpoint_lat'].values.astype(np.float32)
    kp_penalty = df['kp_penalty'].values.astype(np.float32)

    tx_lat, tx_lon = grid_to_latlon_series(df['tx_grid'].values)
    rx_lat, rx_lon = grid_to_latlon_series(df['rx_grid'].values)

    freq_hz = np.array([BAND_TO_HZ.get(int(b), 14_097_100)
                         for b in band], dtype=np.float64)

    return np.column_stack([
        distance / 20000.0,
        np.log10(freq_hz.astype(np.float32)) / 8.0,
        np.sin(2.0 * np.pi * hour / 24.0),
        np.cos(2.0 * np.pi * hour / 24.0),
        np.sin(2.0 * np.pi * azimuth / 360.0),
        np.cos(2.0 * np.pi * azimuth / 360.0),
        np.abs(tx_lat - rx_lat) / 180.0,
        midpoint_lat_raw / 90.0,
        np.sin(2.0 * np.pi * month / 12.0),
        np.cos(2.0 * np.pi * month / 12.0),
        np.cos(2.0 * np.pi * (hour + (tx_lon + rx_lon) / 2.0 / 15.0) / 24.0),
        sfi / 300.0,
        kp_penalty,
    ]).astype(np.float32), tx_lat, tx_lon, rx_lat, rx_lon


# ── Gate Extraction ─────────────────────────────────────────────────────

def extract_gates(model, features, batch_size=16384):
    model.eval()
    sun_gates = []
    storm_gates = []
    with torch.no_grad():
        for i in range(0, len(features), batch_size):
            batch = torch.tensor(features[i:i + batch_size],
                                 dtype=torch.float32, device=DEVICE)
            sun_g, storm_g = model.get_gates(batch)
            sun_gates.append(sun_g.cpu().numpy())
            storm_gates.append(storm_g.cpu().numpy())
    return np.concatenate(sun_gates).flatten(), np.concatenate(storm_gates).flatten()


# ── Geographic Binning ──────────────────────────────────────────────────

def bin_gates(mid_lats, mid_lons, gate_values, bin_lat=BIN_LAT, bin_lon=BIN_LON):
    """Bin gate values by path midpoint into a lat/lon grid."""
    lat_edges = np.arange(-90, 90 + bin_lat, bin_lat)
    lon_edges = np.arange(-180, 180 + bin_lon, bin_lon)

    n_lat = len(lat_edges) - 1
    n_lon = len(lon_edges) - 1

    gate_sum = np.zeros((n_lat, n_lon), dtype=np.float64)
    gate_count = np.zeros((n_lat, n_lon), dtype=np.int64)

    lat_idx = np.clip(((mid_lats - (-90)) / bin_lat).astype(int), 0, n_lat - 1)
    lon_idx = np.clip(((mid_lons - (-180)) / bin_lon).astype(int), 0, n_lon - 1)

    np.add.at(gate_sum, (lat_idx, lon_idx), gate_values)
    np.add.at(gate_count, (lat_idx, lon_idx), 1)

    gate_mean = np.full((n_lat, n_lon), np.nan)
    valid = gate_count >= MIN_SAMPLES
    gate_mean[valid] = gate_sum[valid] / gate_count[valid]

    lat_centers = (lat_edges[:-1] + lat_edges[1:]) / 2
    lon_centers = (lon_edges[:-1] + lon_edges[1:]) / 2
    lon_grid, lat_grid = np.meshgrid(lon_centers, lat_centers)

    return lat_grid, lon_grid, gate_mean, gate_count


# ── Visualization ───────────────────────────────────────────────────────

def plot_vulnerability_map(lat_grid, lon_grid, storm_grid, count_grid, stats,
                           save_path):
    fig = plt.figure(figsize=(16, 10), facecolor='#1a1a2e')

    gs = fig.add_gridspec(2, 2, height_ratios=[3, 1], width_ratios=[40, 1],
                          hspace=0.25, wspace=0.05,
                          left=0.06, right=0.92, top=0.91, bottom=0.06)

    ax_map = fig.add_subplot(gs[0, 0])
    ax_cb = fig.add_subplot(gs[0, 1])
    ax_prof = fig.add_subplot(gs[1, 0])

    # --- Main heatmap ---
    valid = ~np.isnan(storm_grid)
    data_min = np.nanmin(storm_grid)
    data_max = np.nanmax(storm_grid)

    # If range spans 1.0, center on 1.0; otherwise center on data mean
    if data_min < 1.0 < data_max:
        vcenter = 1.0
    else:
        vcenter = np.nanmean(storm_grid)

    vmin = max(0.5, data_min - 0.02)
    vmax = min(2.0, data_max + 0.02)

    # Ensure valid ordering for TwoSlopeNorm
    if vmin >= vcenter:
        vmin = vcenter - 0.01
    if vmax <= vcenter:
        vmax = vcenter + 0.01

    norm = TwoSlopeNorm(vmin=vmin, vcenter=vcenter, vmax=vmax)
    cmap = plt.cm.RdBu_r.copy()
    cmap.set_bad(color='#0d1b2a')  # No-data cells match background

    im = ax_map.pcolormesh(lon_grid, lat_grid, storm_grid,
                           cmap=cmap, norm=norm, shading='auto', rasterized=True)

    # Auroral oval bands: ±60° to ±70°
    for lat_lo, lat_hi, label in [(60, 70, 'N Auroral Zone'),
                                   (-70, -60, 'S Auroral Zone')]:
        ax_map.axhspan(lat_lo, lat_hi, color='lime', alpha=0.12, zorder=2)
        ax_map.axhline(lat_lo, color='lime', ls='--', lw=1.0, alpha=0.7, zorder=3)
        ax_map.axhline(lat_hi, color='lime', ls='--', lw=1.0, alpha=0.7, zorder=3)
        ax_map.text(-175, (lat_lo + lat_hi) / 2, label,
                    color='lime', fontsize=8, va='center', alpha=0.9,
                    fontweight='bold', zorder=4)

    # Reference lines
    ax_map.axhline(0, color='white', ls=':', lw=0.5, alpha=0.3)
    for lat in [-80, -60, -40, -20, 20, 40, 60, 80]:
        ax_map.axhline(lat, color='white', ls=':', lw=0.3, alpha=0.15)
    for lon in range(-180, 181, 30):
        ax_map.axvline(lon, color='white', ls=':', lw=0.3, alpha=0.15)

    ax_map.set_xlim(-180, 180)
    ax_map.set_ylim(-90, 90)
    ax_map.set_xlabel('Midpoint Longitude (°)', color='white', fontsize=10)
    ax_map.set_ylabel('Midpoint Latitude (°)', color='white', fontsize=10)
    ax_map.set_xticks(range(-180, 181, 60))
    ax_map.set_yticks(range(-90, 91, 30))
    ax_map.tick_params(colors='white', labelsize=8)
    ax_map.set_facecolor('#0d1b2a')
    for spine in ax_map.spines.values():
        spine.set_color('white')
        spine.set_linewidth(0.5)

    # Colorbar
    cb = plt.colorbar(im, cax=ax_cb)
    cb.set_label('Storm Gate Value', color='white', fontsize=10)
    cb.ax.tick_params(colors='white', labelsize=8)
    cb.ax.yaxis.set_tick_params(color='white')
    for spine in cb.ax.spines.values():
        spine.set_color('white')

    # Stats text box
    txt = (f"Polar (|lat|>60°):  {stats['polar_mean']:.4f}\n"
           f"Auroral (60°–70°):  {stats['auroral_mean']:.4f}\n"
           f"Mid-lat (20°–60°):  {stats['midlat_mean']:.4f}\n"
           f"Equatorial (<20°):  {stats['eq_mean']:.4f}\n"
           f"Polar/Eq ratio:     {stats['polar_eq_ratio']:.2f}x\n"
           f"Bins ≥{MIN_SAMPLES} paths:    {stats['valid_bins']:,}")
    ax_map.text(0.99, 0.02, txt, transform=ax_map.transAxes,
                fontsize=8, color='white', fontfamily='monospace',
                va='bottom', ha='right', alpha=0.9,
                bbox=dict(boxstyle='round,pad=0.4', facecolor='#0d1b2a',
                          edgecolor='white', alpha=0.8))

    # --- Latitude profile (zonal mean) ---
    lats_1d = lat_grid[:, 0]
    n_lats = storm_grid.shape[0]
    zonal_means = np.zeros(n_lats)
    zonal_stds = np.zeros(n_lats)
    zonal_counts = np.zeros(n_lats, dtype=int)

    for i in range(n_lats):
        row = storm_grid[i, :]
        valid_row = row[~np.isnan(row)]
        if len(valid_row) > 0:
            zonal_means[i] = valid_row.mean()
            zonal_stds[i] = valid_row.std()
            zonal_counts[i] = len(valid_row)
        else:
            zonal_means[i] = np.nan
            zonal_stds[i] = 0

    has_data = ~np.isnan(zonal_means)
    lats_valid = lats_1d[has_data]
    means_valid = zonal_means[has_data]
    stds_valid = zonal_stds[has_data]

    ax_prof.fill_between(lats_valid, means_valid - stds_valid,
                         means_valid + stds_valid,
                         color='#ff6b6b', alpha=0.2)
    ax_prof.plot(lats_valid, means_valid, color='#ff6b6b', lw=2,
                 label='Storm gate (zonal mean ± std)')
    ax_prof.axhline(1.0, color='white', ls=':', lw=0.8, alpha=0.4,
                    label='V10 neutral (1.0)')

    # Auroral bands on profile
    for lat_lo, lat_hi in [(60, 70), (-70, -60)]:
        ax_prof.axvspan(lat_lo, lat_hi, color='lime', alpha=0.1, zorder=0)
        ax_prof.axvline(lat_lo, color='lime', ls='--', lw=0.6, alpha=0.5)
        ax_prof.axvline(lat_hi, color='lime', ls='--', lw=0.6, alpha=0.5)

    ax_prof.set_xlim(-90, 90)
    ax_prof.set_xlabel('Midpoint Latitude (°)', color='white', fontsize=10)
    ax_prof.set_ylabel('Storm Gate', color='white', fontsize=10)
    ax_prof.set_xticks(range(-90, 91, 30))
    ax_prof.tick_params(colors='white', labelsize=8)
    ax_prof.set_facecolor('#0d1b2a')
    ax_prof.legend(loc='upper left', fontsize=8, facecolor='#1a1a2e',
                   edgecolor='white', labelcolor='white')
    for spine in ax_prof.spines.values():
        spine.set_color('white')
        spine.set_linewidth(0.5)

    # Title
    fig.suptitle('IONIS V11 — Geomagnetic Vulnerability Map (MAP-01)',
                 color='white', fontsize=14, fontweight='bold', y=0.97)
    fig.text(0.5, 0.935,
             'Storm gate extracted from 10M real WSPR paths  |  '
             f'{BIN_LAT:.0f}° × {BIN_LON:.0f}° bins (min {MIN_SAMPLES} paths)  |  '
             'Red = High storm sensitivity, Blue = Low',
             color='#b0b0b0', fontsize=9, ha='center')

    fig.savefig(save_path, dpi=150, facecolor=fig.get_facecolor())
    plt.close(fig)


# ── Main ────────────────────────────────────────────────────────────────

def main():
    log.info("IONIS V11 | MAP-01: Geomagnetic Vulnerability Map")
    log.info(f"Device: {DEVICE}")
    log.info(f"Method: Real WSPR data → extract gates → geographic binning")
    log.info(f"Bins: {BIN_LAT:.0f}° lat × {BIN_LON:.0f}° lon, min {MIN_SAMPLES} paths/bin")

    # ── Load checkpoint ──
    log.info(f"\nLoading checkpoint: {CHECKPOINT_PATH}")
    ckpt = torch.load(CHECKPOINT_PATH, weights_only=False, map_location='cpu')
    log.info(f"  Phase C RMSE: {ckpt.get('val_rmse', '?'):.4f} dB")
    log.info(f"  Phase C Pearson: {ckpt.get('val_pearson', '?'):+.4f}")

    model = IonisV11Gate(dnn_dim=DNN_DIM, sidecar_hidden=8)
    model.load_state_dict(ckpt['model_state'])
    model = model.to(DEVICE)
    model.eval()

    # ── Load data ──
    log.info(f"\nLoading {CSV_PATH}...")
    t0 = time.perf_counter()
    df = pd.read_csv(CSV_PATH)
    log.info(f"Loaded {len(df):,} rows in {time.perf_counter() - t0:.1f}s")

    # ── Engineer features ──
    log.info("Engineering features...")
    t0 = time.perf_counter()
    X, tx_lat, tx_lon, rx_lat, rx_lon = engineer_features(df)
    feat_sec = time.perf_counter() - t0
    log.info(f"  {X.shape[0]:,} rows × {X.shape[1]} features in {feat_sec:.1f}s")

    # Compute midpoint lat/lon for geographic binning
    mid_lats = (tx_lat + rx_lat) / 2.0
    mid_lons = (tx_lon + rx_lon) / 2.0

    # ── Extract gates ──
    log.info("Extracting gate values from model...")
    t0 = time.perf_counter()
    sun_gates, storm_gates = extract_gates(model, X)
    gate_sec = time.perf_counter() - t0
    log.info(f"  {len(storm_gates):,} gate values in {gate_sec:.1f}s")

    # Raw gate statistics
    log.info(f"\n  Raw gate statistics (all {len(storm_gates):,} paths):")
    log.info(f"    Storm gate: mean={storm_gates.mean():.4f}, "
             f"std={storm_gates.std():.4f}, "
             f"range=[{storm_gates.min():.4f}, {storm_gates.max():.4f}]")
    log.info(f"    Sun gate:   mean={sun_gates.mean():.4f}, "
             f"std={sun_gates.std():.4f}, "
             f"range=[{sun_gates.min():.4f}, {sun_gates.max():.4f}]")

    # ── Bin by geography ──
    log.info("\nBinning by path midpoint...")
    lat_grid, lon_grid, storm_mean, count_grid = bin_gates(
        mid_lats, mid_lons, storm_gates)
    _, _, sun_mean, _ = bin_gates(mid_lats, mid_lons, sun_gates)

    valid_bins = np.sum(~np.isnan(storm_mean))
    total_bins = storm_mean.size
    log.info(f"  {valid_bins:,} / {total_bins:,} bins have ≥{MIN_SAMPLES} paths")
    log.info(f"  Max paths in a bin: {count_grid.max():,}")

    # ── Zonal Analysis ──
    log.info("\n" + "=" * 70)
    log.info("  STORM GATE GEOGRAPHIC ANALYSIS")
    log.info("=" * 70)

    # Use raw per-path data for zonal stats (more precise than binned)
    polar_mask = np.abs(mid_lats) > 60.0
    midlat_mask = (np.abs(mid_lats) >= 20.0) & (np.abs(mid_lats) <= 60.0)
    eq_mask = np.abs(mid_lats) < 20.0
    auroral_mask = (np.abs(mid_lats) >= 60.0) & (np.abs(mid_lats) <= 70.0)

    polar_mean = storm_gates[polar_mask].mean()
    midlat_mean = storm_gates[midlat_mask].mean()
    eq_mean = storm_gates[eq_mask].mean()
    auroral_mean = storm_gates[auroral_mask].mean()

    log.info(f"\n  Zonal means (from raw paths):")
    log.info(f"    Polar (|lat| > 60°):     {polar_mean:.4f}  "
             f"({polar_mask.sum():>9,} paths)")
    log.info(f"    Auroral (60°–70°):       {auroral_mean:.4f}  "
             f"({auroral_mask.sum():>9,} paths)")
    log.info(f"    Mid-latitude (20°–60°):  {midlat_mean:.4f}  "
             f"({midlat_mask.sum():>9,} paths)")
    log.info(f"    Equatorial (|lat| < 20°):{eq_mean:.4f}  "
             f"({eq_mask.sum():>9,} paths)")

    polar_eq_ratio = polar_mean / eq_mean if eq_mean > 0 else float('inf')
    log.info(f"\n    Polar / Equatorial ratio: {polar_eq_ratio:.4f}x")

    # Auroral oval comparison
    log.info(f"\n  Auroral Oval Comparison:")
    log.info(f"    Physical auroral ovals: 60°–70° N/S (geomagnetic)")
    log.info(f"    Model storm gate in auroral zone: {auroral_mean:.4f}")
    log.info(f"    Model storm gate at equator:      {eq_mean:.4f}")

    if auroral_mean > eq_mean * 1.05:
        log.info(f"    >>> DISCOVERY CONFIRMED: Auroral zone storm sensitivity")
        log.info(f"        is {auroral_mean/eq_mean:.2f}x equatorial level!")
    elif auroral_mean > eq_mean * 1.01:
        log.info(f"    Weak signal: auroral zone slightly elevated "
                 f"({auroral_mean/eq_mean:.3f}x)")
    else:
        log.info(f"    No auroral zone signal detected")

    # 10° latitude profile
    log.info(f"\n  Latitude profile (10° bins, raw path data):")
    log.info(f"    {'Lat Band':>14s}  {'Paths':>10s}  {'Storm μ':>8s}  "
             f"{'Storm σ':>8s}  {'Sun μ':>8s}  {'Bar'}")
    log.info(f"    {'-' * 70}")
    for lo in range(-80, 90, 10):
        hi = lo + 10
        mask = (mid_lats >= lo) & (mid_lats < hi)
        count = mask.sum()
        if count < 100:
            continue
        s_mean = storm_gates[mask].mean()
        s_std = storm_gates[mask].std()
        u_mean = sun_gates[mask].mean()
        # Relative bar: scale so 1.0 = center, show deviation
        deviation = s_mean - 1.0
        if deviation >= 0:
            bar = '▓' * int(deviation * 80)
        else:
            bar = '░' * int(-deviation * 80)
        log.info(f"    {lo:+3d}° to {hi:+3d}°  {count:>10,}  {s_mean:7.4f}   "
                 f"{s_std:7.4f}   {u_mean:7.4f}   {'|' if deviation < 0 else ''}"
                 f"{bar}{'|' if deviation >= 0 else ''}")

    # Sun gate comparison
    log.info(f"\n  Sun gate zonal means:")
    log.info(f"    Polar:      {sun_gates[polar_mask].mean():.4f}")
    log.info(f"    Auroral:    {sun_gates[auroral_mask].mean():.4f}")
    log.info(f"    Mid-lat:    {sun_gates[midlat_mask].mean():.4f}")
    log.info(f"    Equatorial: {sun_gates[eq_mask].mean():.4f}")

    stats = {
        'polar_mean': polar_mean,
        'midlat_mean': midlat_mean,
        'eq_mean': eq_mean,
        'auroral_mean': auroral_mean,
        'polar_eq_ratio': polar_eq_ratio,
        'valid_bins': valid_bins,
    }

    # ── Generate figures ──
    os.makedirs(DOCS_DIR, exist_ok=True)
    docs_path = os.path.join(DOCS_DIR, OUTPUT_PNG)
    training_path = os.path.join(TRAINING_DIR, "figures", OUTPUT_PNG)
    os.makedirs(os.path.dirname(training_path), exist_ok=True)

    log.info(f"\nGenerating visualization...")
    plot_vulnerability_map(lat_grid, lon_grid, storm_mean, count_grid,
                           stats, docs_path)
    log.info(f"  Saved: {docs_path}")

    plot_vulnerability_map(lat_grid, lon_grid, storm_mean, count_grid,
                           stats, training_path)
    log.info(f"  Saved: {training_path}")

    log.info(f"\n{'=' * 70}")
    log.info(f"  MAP-01 COMPLETE")
    log.info(f"{'=' * 70}")
    log.info(f"  Paths processed:        {len(storm_gates):,}")
    log.info(f"  Storm gate global mean: {storm_gates.mean():.4f}")
    log.info(f"  Storm gate global std:  {storm_gates.std():.4f}")
    log.info(f"  Auroral zone mean:      {auroral_mean:.4f}")
    log.info(f"  Equatorial mean:        {eq_mean:.4f}")
    log.info(f"  Polar/Equatorial ratio: {polar_eq_ratio:.4f}x")
    log.info(f"  PNG: {docs_path}")


if __name__ == '__main__':
    main()
